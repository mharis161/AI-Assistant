# System Architecture - PDF Policy Chatbot

## ğŸ“ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                          â”‚
â”‚                   (CLI / API / Web Interface)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CHATBOT LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Policy Chatbot (chatbot.py)                             â”‚  â”‚
â”‚  â”‚  - Query Processing                                      â”‚  â”‚
â”‚  â”‚  - Context Preparation                                   â”‚  â”‚
â”‚  â”‚  - Response Generation                                   â”‚  â”‚
â”‚  â”‚  - Confidence Calculation                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VECTOR STORE LAYER     â”‚  â”‚      LLM LAYER           â”‚
â”‚  (vector_store.py)       â”‚  â”‚   (OpenAI API)           â”‚
â”‚                          â”‚  â”‚                          â”‚
â”‚  - Embedding Generation  â”‚  â”‚  - GPT-4 / GPT-3.5       â”‚
â”‚  - Similarity Search     â”‚  â”‚  - Response Generation   â”‚
â”‚  - ChromaDB Management   â”‚  â”‚  - Context Understanding â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VECTOR DATABASE                               â”‚
â”‚                      (ChromaDB)                                 â”‚
â”‚  - Document Embeddings Storage                                  â”‚
â”‚  - Semantic Search                                              â”‚
â”‚  - Metadata Management                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–²
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INGESTION LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PDF Processor (pdf_processor.py)                        â”‚  â”‚
â”‚  â”‚  - Text Extraction                                       â”‚  â”‚
â”‚  â”‚  - Chunking with Overlap                                 â”‚  â”‚
â”‚  â”‚  - Metadata Extraction                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–²
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA SOURCE                                â”‚
â”‚                   PDF Documents (uploads/)                      â”‚
â”‚  - HR Policies                                                  â”‚
â”‚  - Company Guidelines                                           â”‚
â”‚  - SOPs & Procedures                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow

### 1. Document Ingestion Pipeline

```
PDF Upload â†’ Text Extraction â†’ Chunking â†’ Embedding â†’ Vector Store
```

**Detailed Steps:**

1. **PDF Upload**: User places PDF in `uploads/` folder
2. **Text Extraction** (pdf_processor.py):
   - PyPDF2 extracts text page by page
   - Section headings are identified
   - Metadata is collected (filename, page numbers)
3. **Chunking**:
   - Text split into 800-token chunks
   - 200-token overlap between chunks
   - Preserves context across chunk boundaries
4. **Embedding Generation**:
   - OpenAI text-embedding-ada-002
   - Converts text to 1536-dimensional vectors
5. **Vector Store**:
   - ChromaDB stores embeddings + metadata
   - Enables semantic similarity search

### 2. Query Processing Pipeline

```
User Query â†’ Embedding â†’ Similarity Search â†’ Context Retrieval 
    â†’ LLM Processing â†’ Response + Sources + Confidence
```

**Detailed Steps:**

1. **User Query**: Question entered via CLI/API
2. **Query Embedding**:
   - Query converted to vector using same model
3. **Similarity Search**:
   - ChromaDB finds top K most similar chunks
   - Cosine similarity ranking
4. **Context Filtering**:
   - Chunks filtered by similarity threshold (0.7)
   - Top 5 relevant chunks selected
5. **LLM Processing**:
   - GPT-4 receives system prompt + context + query
   - Temperature: 0.1 (factual, deterministic)
   - Max tokens: 1000
6. **Response Generation**:
   - Answer extracted from context only
   - Source attribution added
   - Confidence calculated from similarity scores

## ğŸ—ï¸ Component Architecture

### Core Modules

#### 1. **config.py**
- Central configuration
- Environment variables
- Hyperparameters
- Path management

#### 2. **pdf_processor.py**
```
PDFProcessor
â”œâ”€â”€ extract_text_from_pdf()
â”œâ”€â”€ chunk_text()
â”œâ”€â”€ _extract_section_heading()
â””â”€â”€ _clean_text()
```

#### 3. **vector_store.py**
```
VectorStore
â”œâ”€â”€ generate_embedding()
â”œâ”€â”€ add_documents()
â”œâ”€â”€ search()
â”œâ”€â”€ clear_database()
â””â”€â”€ get_collection_stats()
```

#### 4. **chatbot.py**
```
PolicyChatbot
â”œâ”€â”€ query()
â”œâ”€â”€ _prepare_context()
â”œâ”€â”€ _generate_response()
â”œâ”€â”€ _calculate_confidence()
â”œâ”€â”€ _extract_sources()
â””â”€â”€ format_response()
```

#### 5. **ingest.py**
- CLI for document ingestion
- Batch processing
- Progress tracking

#### 6. **main.py**
- Interactive chatbot interface
- Command handling
- User interaction

## ğŸ” Security Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Security Layers                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Environment Variables (.env)                            â”‚
â”‚     - API keys isolated from code                           â”‚
â”‚     - Never committed to version control                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. Input Validation                                        â”‚
â”‚     - File type checking                                    â”‚
â”‚     - Path sanitization                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. Output Sanitization                                     â”‚
â”‚     - LLM output validation                                 â”‚
â”‚     - Source attribution verification                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. Access Control                                          â”‚
â”‚     - Local file system only                                â”‚
â”‚     - No external network access (except OpenAI API)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Model

### Document Chunk Structure
```json
{
  "chunk_id": 42,
  "text": "Employees are entitled to...",
  "metadata": {
    "filename": "hr_policy.pdf",
    "page_number": 15,
    "section": "Leave Policy",
    "chunk_index": 42,
    "token_count": 750
  }
}
```

### Search Result Structure
```json
{
  "query": "annual leave policy",
  "results": [
    {
      "text": "Chunk text...",
      "metadata": {...},
      "similarity_score": 0.89
    }
  ],
  "total_results": 5
}
```

### Response Structure
```json
{
  "answer": "According to...",
  "sources": [
    {
      "document": "hr_policy.pdf",
      "page": 15,
      "section": "Leave Policy",
      "similarity": 0.89
    }
  ],
  "confidence": "High",
  "context_chunks": 5
}
```

## âš¡ Performance Optimization

### 1. Chunking Strategy
- **Size**: 800 tokens (optimal for context/granularity)
- **Overlap**: 200 tokens (preserves context)
- **Trade-off**: Memory vs. Accuracy

### 2. Embedding Caching
- Cache frequently used embeddings
- Reduce API calls
- Faster response time

### 3. Batch Processing
- Process multiple documents together
- Parallel embedding generation possible
- Progress tracking

### 4. Vector Database Optimization
- ChromaDB persistent storage
- Fast similarity search (ANN)
- Metadata indexing

## ğŸ”§ Configuration Parameters

| Parameter | Default | Purpose |
|-----------|---------|---------|
| CHUNK_SIZE | 800 | Tokens per chunk |
| CHUNK_OVERLAP | 200 | Overlap between chunks |
| TOP_K_RESULTS | 5 | Chunks retrieved |
| SIMILARITY_THRESHOLD | 0.7 | Minimum relevance |
| LLM_MODEL | gpt-4 | Language model |
| TEMPERATURE | 0.1 | Response randomness |
| CONFIDENCE_HIGH | 0.85 | High confidence threshold |
| CONFIDENCE_MEDIUM | 0.70 | Medium confidence threshold |

## ğŸš€ Scalability Considerations

### Current Design (Single User)
- Local ChromaDB
- Synchronous processing
- CLI interface

### Production Scalability
- **Multi-User**: Add authentication layer
- **Distributed Vector DB**: Pinecone, Qdrant Cloud
- **API Server**: FastAPI/Flask wrapper
- **Caching**: Redis for embeddings
- **Load Balancing**: Multiple LLM endpoints
- **Monitoring**: Logging, metrics, alerts

## ğŸ” Error Handling

```
User Input â†’ Validation â†’ Processing â†’ Error Handling â†’ Response
                â†“             â†“             â†“
            InvalidInput  NoContext    APIError
                â†“             â†“             â†“
            UserMessage   LowConfidence  Retry/Fallback
```

## ğŸ“ˆ Metrics & Monitoring

### Key Metrics
- **Ingestion**: Documents processed, chunks created
- **Search**: Average similarity score, retrieval time
- **Response**: Confidence distribution, source coverage
- **API**: OpenAI token usage, costs

### Logging Points
- Document ingestion start/complete
- Embedding generation (batches)
- Search queries and results
- LLM API calls
- Errors and exceptions

## ğŸ¯ Design Principles

1. **Single Source of Truth**: Only PDF documents
2. **Transparency**: Always show sources
3. **Accuracy over Creativity**: Low temperature, strict prompts
4. **Fail-Safe**: Clear "not found" messages
5. **Modularity**: Swappable components (LLM, Vector DB)
6. **Maintainability**: Clear separation of concerns
