# PDF-Based Policy Chatbot

Enterprise Document-QA Assistant for HR policies, company rules, contracts, procedures, SOPs, and guidelines.

## ğŸ¯ Features

- **Strict Document-Based Answers**: Only responds from uploaded PDF content
- **Vector Search**: Uses embeddings for semantic search across documents
- **Source Attribution**: Always cites the document, page, and section
- **Confidence Scoring**: Indicates reliability of answers (High/Medium/Low)
- **Multi-Document Support**: Process multiple PDFs simultaneously
- **No Hallucination**: Never guesses or uses external knowledge

## ğŸ“‹ Supported Use Cases

- HR Policies & Procedures
- Leave policies
- Travel entitlement
- Payroll rules
- Employee benefits
- Medical coverage
- Company guidelines
- Compliance documents
- SOPs
- Contracts or agreements

## ğŸš€ Quick Start

### 1. Installation

```bash
# Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate  # On Windows
# source venv/bin/activate  # On Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

Create a `.env` file:

```bash
cp .env.example .env
```

Edit `.env` and add your OpenAI API key:

```
OPENAI_API_KEY=sk-your-api-key-here
```

### 3. Upload Documents

Place your PDF files in the `uploads/` folder:

```bash
# The uploads folder is created automatically
# Add your HR policy PDFs there
```

### 4. Ingest Documents

Process your PDFs into the vector database:

```bash
# Process all PDFs in uploads folder
python ingest.py

# Process specific files
python ingest.py --files path/to/policy1.pdf path/to/policy2.pdf

# Clear existing data and re-ingest
python ingest.py --clear
```

### 5. Start Chatbot

```bash
python main.py
```

## ğŸ’¬ Usage Examples

```
ğŸ™‹ Your Question: How many annual leaves does a permanent employee get?

ANSWER:
According to the HR Policy Document â†’ Leave Policy â†’ Section 4.1, 
a permanent employee is entitled to 14 days of annual leave per year.

SOURCE (Matched from PDF):
  â€¢ hr_policy.pdf | Page 12 | Section: Leave Policy | Relevance: 94%

CONFIDENCE: High
```

```
ğŸ™‹ Your Question: Can I work from home for 3 days?

ANSWER:
I could not find any policy related to remote work or work-from-home 
in the provided documents.

CONFIDENCE: Low
```

## ğŸ“ Project Structure

```
AIAssistant/
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ pdf_processor.py       # PDF extraction and chunking
â”œâ”€â”€ vector_store.py        # Embeddings and vector database
â”œâ”€â”€ chatbot.py            # Query processing and LLM integration
â”œâ”€â”€ ingest.py             # Document ingestion script
â”œâ”€â”€ main.py               # Interactive CLI application
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env.example          # Environment variables template
â”œâ”€â”€ uploads/              # Place PDF files here
â””â”€â”€ vector_db/            # ChromaDB storage (auto-created)
```

## âš™ï¸ Configuration Options

Edit `config.py` to customize:

- **Chunk Size**: Default 800 tokens
- **Chunk Overlap**: Default 200 tokens
- **Top K Results**: Default 5 chunks
- **LLM Model**: gpt-4 or gpt-3.5-turbo
- **Similarity Threshold**: Minimum 0.7
- **Confidence Levels**: High (0.85), Medium (0.70), Low (0.50)

## ğŸ¨ Architecture

```
User Query
    â†“
[Query Processing]
    â†“
[Embedding Generation] â†’ OpenAI API
    â†“
[Vector Search] â†’ ChromaDB
    â†“
[Context Retrieval] â†’ Top K Chunks
    â†“
[LLM Response] â†’ GPT-4 with Context
    â†“
[Answer + Sources + Confidence]
```

## ğŸ”§ Advanced Usage

### Custom Vector Database

To use Pinecone or Qdrant instead of ChromaDB, modify `vector_store.py`:

```python
# For Pinecone
import pinecone
# Initialize and use Pinecone client

# For Qdrant
from qdrant_client import QdrantClient
# Initialize and use Qdrant client
```

### API Integration

Use the chatbot programmatically:

```python
from chatbot import PolicyChatbot

chatbot = PolicyChatbot()
response = chatbot.query("What is the leave policy?")
print(response['answer'])
```

## ğŸ›¡ï¸ Key Constraints

1. **Strictly Factual**: No assumptions or external knowledge
2. **Neutral & Professional**: Enterprise-grade responses
3. **No Hallucination**: Clear "not found" messages when appropriate
4. **Source Attribution**: Always cite document sources
5. **Never Reinterpret**: Exact policy wording only

## ğŸ“ Commands

- `help` - Show usage tips
- `stats` - Display database statistics
- `clear` - Clear screen
- `quit/exit` - Exit chatbot

## ğŸ”’ Security Notes

- Keep your `.env` file secure
- Never commit API keys to version control
- Use environment variables for sensitive data
- Consider implementing user authentication for production

## ğŸ› Troubleshooting

**No documents found:**
```bash
# Check if PDFs are in the uploads folder
# Re-run ingestion: python ingest.py --clear
```

**Low confidence answers:**
```bash
# Try rephrasing your question
# Check if the information exists in your PDFs
# Lower SIMILARITY_THRESHOLD in config.py
```

**API errors:**
```bash
# Verify OPENAI_API_KEY in .env file
# Check API quota and billing
```

## ğŸ“„ License

This project is provided as-is for enterprise document Q&A purposes.

## ğŸ¤ Contributing

This is a complete, production-ready implementation. Customize as needed for your specific use case.
